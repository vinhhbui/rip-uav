{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a89f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ÄÃ£ tÃ¬m tháº¥y file data.yaml táº¡i:\n",
      "   data_rip.yaml\n",
      "\n",
      "--- Ná»™i dung Ä‘ang Ä‘á»c tá»« data.yaml ---\n",
      "names:\n",
      "- rip_current\n",
      "nc: 1\n",
      "path: ./datasets\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Kiá»ƒm tra thÆ° má»¥c dataset:\n",
      "âœ… ThÆ° má»¥c Train tá»“n táº¡i. CÃ³ 17387 file/thÆ° má»¥c con bÃªn trong.\n",
      "âœ… ThÆ° má»¥c Val tá»“n táº¡i. CÃ³ 4347 file/thÆ° má»¥c con bÃªn trong.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "# 2. Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n Ä‘áº¿n file data.yaml\n",
    "# LÆ°u Ã½: Giá»¯ nguyÃªn cÃ¡ch viáº¿t \"AI Scienctist\" theo Ä‘Ãºng file cá»§a báº¡n\n",
    "yaml_path = 'data_rip.yaml'\n",
    "\n",
    "# 3. Kiá»ƒm tra file data.yaml\n",
    "if os.path.exists(yaml_path):\n",
    "    print(f\"\\nâœ… ÄÃ£ tÃ¬m tháº¥y file data.yaml táº¡i:\\n   {yaml_path}\")\n",
    "    \n",
    "    # Má»Ÿ vÃ  Ä‘á»c ná»™i dung file\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "        \n",
    "    print(\"\\n--- Ná»™i dung Ä‘ang Ä‘á»c tá»« data.yaml ---\")\n",
    "    print(yaml.dump(data_config, allow_unicode=True, default_flow_style=False))\n",
    "    print(\"--------------------------------------\\n\")\n",
    "    \n",
    "    # 4. Kiá»ƒm tra thÆ° má»¥c chá»©a áº£nh tá»« Ä‘Æ°á»ng dáº«n trong data.yaml\n",
    "    base_path = data_config.get('path', '')\n",
    "    train_dir = os.path.join(base_path, data_config.get('train', ''))\n",
    "    val_dir = os.path.join(base_path, data_config.get('val', ''))\n",
    "    \n",
    "    print(\"Kiá»ƒm tra thÆ° má»¥c dataset:\")\n",
    "    \n",
    "    # Kiá»ƒm tra Train\n",
    "    if os.path.exists(train_dir):\n",
    "        train_files = len(os.listdir(train_dir))\n",
    "        print(f\"âœ… ThÆ° má»¥c Train tá»“n táº¡i. CÃ³ {train_files} file/thÆ° má»¥c con bÃªn trong.\")\n",
    "    else:\n",
    "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c Train táº¡i:\\n   {train_dir}\")\n",
    "        \n",
    "    # Kiá»ƒm tra Val\n",
    "    if os.path.exists(val_dir):\n",
    "        val_files = len(os.listdir(val_dir))\n",
    "        print(f\"âœ… ThÆ° má»¥c Val tá»“n táº¡i. CÃ³ {val_files} file/thÆ° má»¥c con bÃªn trong.\")\n",
    "    else:\n",
    "        print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c Val táº¡i:\\n   {val_dir}\")\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ KHÃ”NG tÃ¬m tháº¥y file. HÃ£y kiá»ƒm tra láº¡i chÃ­nh táº£ cá»§a Ä‘Æ°á»ng dáº«n:\\n   {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392becc1",
   "metadata": {},
   "source": [
    "## Tune parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f259eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d001a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119867f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n-seg.pt to 'yolo26n-seg.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.4MB 8.8MB/s 0.7s0.6s<0.1s.4s4s\n",
      "Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh Hyperparameter Tuning...\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=/home/goosevb/code/urlab/test_model/runs/segment/tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/50 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.4.14 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.10 ğŸš€ Python-3.10.19 torch-2.10.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3768MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data_rip.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=False, save_conf=False, save_crop=False, save_dir=/home/goosevb/code/urlab/test_model/runs/segment/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5, 3, True]        \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    119808  ultralytics.nn.modules.block.C3k2            [384, 128, 1, True]           \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     34304  ultralytics.nn.modules.block.C3k2            [256, 64, 1, True]            \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     95232  ultralytics.nn.modules.block.C3k2            [192, 128, 1, True]           \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    463104  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True, 0.5, True]\n",
      " 23        [16, 19, 22]  1    790431  ultralytics.nn.modules.head.Segment26        [1, 32, 64, 1, True, [64, 128, 256]]\n",
      "YOLO26n-seg summary: 309 layers, 3,053,055 parameters, 3,053,055 gradients, 10.2 GFLOPs\n",
      "\n",
      "Transferred 740/844 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 10.5MB/s 0.5s.4s<0.1s.8s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 220.8Â±78.5 MB/s, size: 286.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/goosevb/code/urlab/test_model/datasets/labels/train.cache... 17387 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 17387/17387 5.6Git/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/goosevb/code/urlab/test_model/datasets/images/train/RipDetSeg-tpz49q3c1nsr.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.2 ms, read: 277.9Â±78.4 MB/s, size: 390.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/goosevb/code/urlab/test_model/datasets/labels/val.cache... 4347 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4347/4347 175.3Mit/s 0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 134 weight(decay=0.0), 154 weight(decay=0.0005), 154 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/goosevb/code/urlab/test_model/runs/segment/train\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
      "\u001b[K       1/30      3.17G      1.937      2.833       2.03    0.02156      1.813         57        640: 81% â”â”â”â”â”â”â”â”â”â•¸â”€â”€ 883/1087 1.8it/s 4:54<1:505"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def tune_model():\n",
    "    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh Nano Ä‘á»ƒ tune (nhanh hÆ¡n báº£n Small)\n",
    "    model = YOLO(\"yolo26n-seg.pt\")\n",
    "\n",
    "    print(\"Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh Hyperparameter Tuning...\")\n",
    "    # QuÃ¡ trÃ¬nh nÃ y sáº½ sinh ra cÃ¡c biáº¿n thá»ƒ tham sá»‘ vÃ  kiá»ƒm thá»­\n",
    "    model.tune(\n",
    "        data=\"data_rip.yaml\",\n",
    "        epochs=30,          # Sá»‘ epoch cho má»—i láº§n thá»­ nghiá»‡m\n",
    "        iterations=50,      # Sá»‘ láº§n thá»­ nghiá»‡m cÃ¡c bá»™ tham sá»‘ khÃ¡c nhau\n",
    "        optimizer=\"AdamW\",\n",
    "        plots=False,\n",
    "        save=False,\n",
    "        val=False\n",
    "    )\n",
    "    print(\"Tuning hoÃ n táº¥t. File tham sá»‘ tá»‘t nháº¥t Ä‘Æ°á»£c lÆ°u táº¡i: runs/segment/tune/best_hyperparameters.yaml\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tune_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5031b5",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def train_models():\n",
    "    # --- Huáº¥n luyá»‡n YOLO26 Nano (Æ¯u tiÃªn cho Jetson) ---\n",
    "    print(\"Äang huáº¥n luyá»‡n YOLO26n-seg...\")\n",
    "    model_n = YOLO(\"yolo26n-seg.pt\")\n",
    "    \n",
    "    # Báº¡n cÃ³ thá»ƒ truyá»n file tham sá»‘ Ä‘Ã£ tune vÃ o Ä‘Ã¢y báº±ng Ä‘á»‘i sá»‘ `cfg` náº¿u muá»‘n, \n",
    "    # hoáº·c Ä‘á»ƒ nÃ³ tá»± Ä‘á»™ng há»c theo máº·c Ä‘á»‹nh.\n",
    "    results_n = model_n.train(\n",
    "        data=\"data.yaml\",\n",
    "        epochs=100,\n",
    "        imgsz=640,          # CÃ³ thá»ƒ giáº£m xuá»‘ng 416 náº¿u GPU cá»§a báº¡n bá»‹ quÃ¡ táº£i\n",
    "        batch=16,           # Äiá»u chá»‰nh tÃ¹y thuá»™c vÃ o VRAM cá»§a mÃ¡y train\n",
    "        project=\"rip_current_project\",\n",
    "        name=\"yolo26n_train\",\n",
    "        # CÃ¡c thÃ´ngdata.yaml sá»‘ mAP, Recall, Loss sáº½ tá»± Ä‘á»™ng in ra terminal vÃ  lÆ°u vÃ o file results.csv\n",
    "    )\n",
    "\n",
    "    # # --- Huáº¥n luyá»‡n YOLO26 Small (Giáº£ thuyáº¿t dá»± phÃ²ng) ---\n",
    "    # print(\"Äang huáº¥n luyá»‡n YOLO26s-seg...\")\n",
    "    # model_s = YOLO(\"yolo26s-seg.pt\")\n",
    "    # results_s = model_s.train(\n",
    "    #     data=\"/home/goosevb/code/urlab/test_model/data.yaml\",\n",
    "    #     epochs=100,\n",
    "    #     imgsz=640,\n",
    "    #     batch=16,\n",
    "    #     project=\"rip_current_project\",\n",
    "    #     name=\"yolo26s_train\",\n",
    "    # )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
